# Parkinson's Disease Detection
### Overview
This project focuses on developing a machine learning model for the early detection of Parkinson's disease. Leveraging biomedical data and machine learning algorithms, the goal is to provide a reliable and accurate tool for proactive healthcare interventions.

### Table of Contents 
Background |
Features |
Usage |
Dataset |
Model Development |
Results |

### Background: 
Parkinson's disease is a neurodegenerative disorder that affects millions worldwide. Early detection is crucial for effective management and treatment. This project aims to contribute to early diagnosis through the application of machine learning techniques on relevant patient data.

### Features:
**Classification Algorithms:** Utilized logistic regression, support vector machines, decision 
trees, random forest, na√Øve bayes and k-neighbors for predictive modeling.

**Feature Selection:** Implemented feature selection techniques to identify key factors contributing to Parkinson's disease.

**Model Interpretability:** Emphasized interpretability for clear insights into the factors influencing disease detection.

### Usage:
Open the Jupyter notebook 'Detection of Parkinsons Disease.ipynb' for a detailed walkthrough of the project.
Explore the csv file name 'parkinsons' for the dataset used.

### Dataset:
The dataset used in this project is the 'parkinsons' is provided by Acmegrade Pvt Ltd. contains the medical data of patients which plays a crucial role in achieving the goals of this project.
- **Source:** Acmegrade Pvt Ltd.
- **Features:** The dataset 'parkinsons' consists of 194 rows and 24 columns that were instrumental in training the machine learning model.
- **Format:** The data is available in CSV format.

### Model Development:
Developed using Python and Jupyter Notebooks.
Model training and evaluation details can be found in the notebook 'Detection of Parkinsons Disease.ipynb'.
### Results:
1. Logistic Regression achieved 85.2% of accuracy on training data and 94.4% of accuracy on testing data.
2. Random Forest Classifier achieved 100% of accuracy on training data and 94.8% of accuracy on testing data.
3. Decision Tree Classifier achieved 100% of accuracy on training data and 92.3% of accuracy on testing data.
4. Naive Bayes - GaussianNB achieved 68% of accuracy on training data and 54.3% of accuracy on testing data.
5. Support Vector Classifier achieved 87% of accuracy on training data and 94.8% of accuracy on testing data.
6. K-Neighbors Classifier achieved 87% of accuracy on training data and 92.3% of accuracy on testing data.
